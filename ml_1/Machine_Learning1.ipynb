{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "Ml8SUOSJTVkG"
      },
      "outputs": [],
      "source": [
        "# Manipulação de dados\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import math\n",
        "# Visualização de dados\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Machine Learning \n",
        "from sklearn import metrics # analisa a acurácia de nossos modelos\n",
        "# Ocultando Warnings indesejados\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.datasets import load_breast_cancer #importando a base de dados nativas no sklearn\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bY_cGDGUj2Xs"
      },
      "source": [
        "### Funções auxiliares\n",
        "\n",
        "\n",
        "Reta = Hipotese = $$ w_0 + w_1*X $$\n",
        "\n",
        "###Sigmoide\n",
        "Sigmoide = $$ \\frac{1}{1+e^{-x}} $$\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "Re_RxULMj6p0"
      },
      "outputs": [],
      "source": [
        "def sigmoide(x):\n",
        "  return 1/(1+math.exp(-x))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hQ9V4BZe22Fy"
      },
      "source": [
        "### Regressão Linear"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NrjOHu-DY3cf"
      },
      "source": [
        "###Erro Medio Quadrático  MSE\n",
        "\n",
        "MSE(Erro Médio Quadrático) = $$ \\frac{1}{m}∑_{i=0}^m (y'_i - y_i)^2 $$\n",
        "\n",
        "sendo y' = $ w_0 + w_1*X $\n",
        "\n",
        "\n",
        "###Gradiente descendente 1 variavel\n",
        "\n",
        "\n",
        "Repita n vezes{\n",
        "  $$ w_0 := w_0 - αΔ_{w_0} $$\n",
        "  $$ w_1 := w_1 - αΔ_{w_1} $$\n",
        "}\n",
        "\n",
        "###Gradiente Descendente\n",
        "\n",
        "Sendo $ α $, taxa de aprendizado \\\\\n",
        "Sendo $Δ_{w_i} $, gradiente(derivada)\n",
        "\n",
        "$$ Δ_{w_0} = \\frac{δJ}{δw_0} J(w_0, w_1) $$\n",
        "\n",
        "$$ Δ_{w_1} = \\frac{δJ}{δw_0} J(w_0, w_1) $$\n",
        "\n",
        "Sendo MSE = $ J(w_0, w_1) $\n",
        "\n",
        "\n",
        "para $Δ_{w_0}$\n",
        "\\\n",
        "$$ Δ_{w_0} = \\frac{dJ}{dw_0} \\frac{1}{2m} ∑_{i=0}^m (y' - y)^2 $$\n",
        "\\\n",
        "\\\n",
        "$$ Δ_{w_0} = \\frac{dJ}{dw_1} \\frac{1}{2m} ∑_{i=0}^m ( (w_0 + w_1*X_i) - y)^2 $$\n",
        "\\\n",
        "\\\n",
        "$$ Δ_{w_0} = \\frac{1}{2m} ∑_{i=0}^m \\frac{dJ}{dw_0}( (w_0 + w_1*X_i) - y)^2 $$\n",
        "\\\n",
        "\\\n",
        "$$ Δ_{w_0} = \\frac{1}{m} ∑_{i=0}^m ( (w_0 + w_1X) - y)$$\n",
        "\\\n",
        "\\\n",
        "$$ Δ_{w_0} = \\frac{1}{m} ∑_{i=0}^m ( y' - y)$$\n",
        "\\\n",
        "\\\n",
        "\\\n",
        "\\\n",
        "para $Δ_{w_1}$\n",
        "\\\n",
        "$$ Δ_{w_1} = \\frac{dJ}{dw_1} \\frac{1}{2m} ∑_{i=0}^m (y' - y)^2 $$\n",
        "\\\n",
        "\\\n",
        "$$ Δ_{w_1} = \\frac{dJ}{dw_1} \\frac{1}{2m} ∑_{i=0}^m ( (w_0 + w_1*X_i) - y)^2 $$\n",
        "\\\n",
        "\\\n",
        "$$ Δ_{w_1} = \\frac{1}{2m} ∑_{i=0}^m \\frac{dJ}{dw_1}( (w_0 + w_1*X_i) - y)^2 $$\n",
        "\\\n",
        "\\\n",
        "$$ Δ_{w_1} = \\frac{1}{2m} ∑_{i=0}^m 2( (w_0 + w_1*X_i) - y) (X_i) $$\n",
        "\\\n",
        "\\\n",
        "$$ Δ_{w_1} = \\frac{1}{m} ∑_{i=0}^m (y' - y) (X_i) $$\n",
        "\n",
        "###Gradiente Descendente Atualizado\n",
        "Repetir n vezes{\n",
        "  $$w_0 := w_0 - α \\frac{1}{m} ∑_{i=0}^m (y'_i-y_i) $$\n",
        "\\\n",
        "  $$w_1 := w_1 - α \\frac{1}{m} ∑_{i=0}^m x_i(y'_i - y_i) $$\n",
        "\n",
        "}\n",
        "\n",
        "\n",
        "###Custo:\n",
        "\n",
        "$$ \\frac{1}{m} ∑_{i=0}^m ( y'_i - y_i)$$\n",
        "\n",
        "\n",
        "###Algoritmo\n",
        "\n",
        "#### Hyperparametros:\n",
        "lr = Learning Rate = $α$ \\\n",
        "epochs = Numero de iterações = $n$ \\\n",
        "\n",
        "#### Entradas\n",
        "x = features \\\n",
        "y = ground truth \\\n",
        "\\\n",
        "inicia-se os pesos $w_0, w_1$, exemplo \\\n",
        "$$w_0 = 0.1 $$ \\\n",
        "$$w_1 = 0.1 $$\\\n",
        "\\\n",
        "e seta os hiperparametros, exemplo \\\n",
        "$$lr = 0.1  $$ \\\\\n",
        "$$epochs = 10 $$\n",
        "\n",
        "para cada iteração até o numero de epocas: \n",
        "  calcular os erros w0, w1 e o custo: \\\n",
        "\n",
        "  $$ y' = w_0 + w_1*X $$ \\\\\n",
        "\n",
        "  $$ erro_{w0} =  \\frac{1}{m} ∑_{i=0}^m ( y'_i - y_i) $$ \\\\\n",
        "\n",
        "   $$ erro_{w1} =  \\frac{1}{m} ∑_{i=0}^m x_i( y'_i - y_i) $$ \\\\\n",
        "\n",
        "   $$ custo = \\frac{1}{m} ∑_{i=0}^m ( y'_i - y_i)$$\n",
        "\n",
        "calcule os novos pesos: \\\n",
        "\n",
        "$$ w_0 = w_0 - erro_{w0} $$ \\\\\n",
        "$$ w_1 = w_1 - erro_{w1} $$\n",
        "\n",
        "retorna $w_0,\\ w_1$, custo\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "Ta9AcZMKw8PG"
      },
      "outputs": [],
      "source": [
        "## Função de custo\n",
        "\n",
        "#Mean Square Error - Erro Médio Quadrático\n",
        "def MSE(predict, ground_truth):\n",
        "  m = predict.size\n",
        "  erro = sum((predict-ground_truth)**2)\n",
        "  return erro/(2*m)\n",
        "\n",
        "def cost(x, y, w0, w1):\n",
        "  predict = np.asarray([y_hat(x[i], w0, w1) for i in range(len(x))])\n",
        "  return 2*MSE(predict, y)\n",
        "\n",
        "\n",
        "## valores preditos\n",
        "def y_hat(x, w0, w1):\n",
        "  return w0 + w1*x\n",
        "\n",
        "\n",
        "## plotar linha\n",
        "def plot_line(x, y, w0, w1):\n",
        "  x_values = [i for i in range(int(min(x))-1, int(max(x))+2)]\n",
        "  y_values = [y_hat(x, w0, w1) for x in x_values]\n",
        "  plt.plot(x_values, y_values)\n",
        "  plt.plot(x, y, 'bo')\n",
        "\n",
        "\n",
        "##passo do gradiente descendente\n",
        "##x = vetor de features\n",
        "##y = ground_truth\n",
        "\n",
        "class LinearRegression:\n",
        "\n",
        "  def __init__(self, lr, epochs):\n",
        "    self.lr = lr\n",
        "    self.epochs = epochs\n",
        "    self.w0 = 0.1\n",
        "    self.w1 = 0.1\n",
        "\n",
        "  def initWeight(self):\n",
        "    self.w0 = 0.1\n",
        "    self.w1 = 0.1\n",
        "\n",
        "  def gradientDescStep(self, x, y):\n",
        "    erro_w0 = 0\n",
        "    erro_w1 = 0\n",
        "    m = len(x)\n",
        "\n",
        "    for i in range(m):\n",
        "      erro_w0 += y_hat(y[i], self.w0, self.w1)-y[i]\n",
        "      erro_w1 += y_hat(y[i], self.w0, self.w1)-y[i]*x[i]\n",
        "      \n",
        "    w0_n = self.w0-(lr/m)*erro_w0\n",
        "    w1_n = self.w1-(lr/m)*erro_w1\n",
        "    return w0_n, w1_n\n",
        "\n",
        "  ##algoritmo de gradiente descendente\n",
        "  def gradientDesc(self, x, y):\n",
        "    custo = []\n",
        "    for i in range(epochs):\n",
        "      self.w0, self.w1 = self.gradientDescStep(x, y)\n",
        "      custo.append(cost(x, y, self.w0, self.w1))\n",
        "      #print(\"epoch: \", i)\n",
        "      #print(\"custo: \", custo[i])\n",
        "    return self.w0, self.w1, custo\n",
        "\n",
        "  def run(self, x, y):\n",
        "    return self.gradientDesc(x, y)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "id": "MQAjJWY0KWZc",
        "outputId": "e90848eb-bf6f-46e4-bbca-7cd30520445a"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "### Teste funções\n",
        "\n",
        "lr = 0.01\n",
        "epochs = 40\n",
        "\n",
        "x = [0.5, 2.2, 2.0]\n",
        "y = [2.0, 2.5, 1.4]\n",
        "\n",
        "rl = LinearRegression(lr, epochs)\n",
        "\n",
        "w0, w1, custo = rl.run(x, y)\n",
        "\n",
        "plot_line(x, y, w0, w1 )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ir0SKGaVY8ht"
      },
      "source": [
        "### Multiplas Variaveis\n",
        "\n",
        "$$ y' = w_0X_0+ w_1X_1 + w_2X_2 + ... +w_nX_n$$\n",
        "\n",
        "sendo $X_0 = 1$\n",
        "\n",
        "#### Isso pode ser escrito na forma de 2 vetores\n",
        "\n",
        "$$ X_{features} = \\begin{bmatrix}\n",
        "X_0 \\\\\n",
        "X_1 \\\\\n",
        "X_2 \\\\\n",
        ". \\\\\n",
        ". \\\\\n",
        ". \\\\\n",
        "X_n \\\\\n",
        "\\end{bmatrix} \n",
        "\\\n",
        "w_{pesos} = \\begin{bmatrix}\n",
        "w_0 \\\\\n",
        "w_1 \\\\\n",
        "w_2 \\\\\n",
        ". \\\\\n",
        ". \\\\\n",
        ". \\\\\n",
        "w_n \\\\\n",
        "\\end{bmatrix}\n",
        "$$\n",
        "\n",
        "####Gradiente com Multiplas variaveis\n",
        "\n",
        "$$w_0 := w_0 - α \\frac{1}{m} \\sum_{i=1}^m (y'_i - y_i) X_0^i$$\n",
        "\n",
        "$$w_1 := w_1 - α \\frac{1}{m} \\sum_{i=1}^m (y'_i - y_i) X_1^i$$\n",
        "\n",
        "$$w_2 := w_2 - α \\frac{1}{m} \\sum_{i=1}^m (y'_i - y_i) X_2^i$$\n",
        "\n",
        "$$w_n := w_n - α \\frac{1}{m} \\sum_{i=1}^m (y'_i - y_i) X_n^i$$\n",
        "\n",
        "\n",
        "para cada j em w {\n",
        "  $$w_j := w_j - α \\frac{1}{m} \\sum_{i=1}^m (y'_i - y_i) X_j^i$$\n",
        "}\n",
        "\n",
        "####A hipotese\n",
        "\n",
        "$$y' = w^TX$$\n",
        "\n",
        "sendo assim\n",
        "\n",
        "\n",
        "para cada j em w {\n",
        "  $$w_j := w_j - α \\frac{1}{m} \\sum_{i=1}^m (w^t_iX_i - y_i) X_j^i$$\n",
        "}\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### A ser implementado"
      ],
      "metadata": {
        "id": "PUR90Nw1k_6N"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "knlciVt5L6xi"
      },
      "source": [
        "### Regressão Logistica\n",
        "\n",
        "\n",
        "####Sigmoide \n",
        "$$ y' = \\frac{1}{1+e^{w^TX}} $$\n",
        "\n",
        "\n",
        "####Funão de erro (Binary Cross Entropy):\n",
        "\n",
        "$$ -y \\log{(y')}-(1-y) \\log{(1-y')} $$\n",
        "\n",
        "\n",
        "####Custo Médio:\n",
        "$$ \\frac{1}{m} \\sum_{i=1}^{m} BCE $$\n",
        "\\\n",
        "$$ \\frac{1}{m} \\sum_{i=1}^{m} -y \\log{(y')}-(1-y) \\log{(1-y')} $$\n",
        "\n",
        "\n",
        "#### Otimização com Gradiente:\n",
        "\n",
        "para cada j em w {\n",
        "  $$w_j := w_j - α \\frac{1}{m} \\sum_{i=1}^m ( \\frac{1}{1+e^{w^TX}} - y_i) X_j^i$$\n",
        "}\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "t8bif_xRlzya"
      },
      "outputs": [],
      "source": [
        "def sigmoide(z):\n",
        "  return 1/(1+np.exp(-z))\n",
        "\n",
        "def extendX(x):\n",
        "  m = x.shape[0]                      #número de linhas\n",
        "  return np.concatenate((np.ones([m, 1]), x), axis=1)\n",
        "\n",
        "def binaryCrossEntropy(w, x, y):\n",
        "  y_ = sigmoide(x@w.T)\n",
        "  return (-y*np.log(y_))-((1-y)*np.log(1-y_))\n",
        "\n",
        "def meanCost(w, x, y):\n",
        "  m = y.shape\n",
        "  return sum(binaryCrossEntropy(w, x, y))/m\n",
        "\n",
        "class LogisticRegression:\n",
        "\n",
        "  def __init__(self, lr, epochs, x_train, y_train, x_test, y_test):\n",
        "    self.lr = lr\n",
        "    self.epochs = epochs\n",
        "    self.x_train = x_train\n",
        "    self.y_train = y_train\n",
        "    self.x_test = x_test\n",
        "    self.y_test = y_test\n",
        "    self.w = np.ones(x_train.shape[1])/10\n",
        "\n",
        "\n",
        "  def logisticGradientDesc(self, w, x, y, lr, epochs):\n",
        "    m = x.shape[1]\n",
        "    y_ = np.zeros(1)\n",
        "    #print(m)\n",
        "    cost = []\n",
        "    for i in range(epochs):\n",
        "      y_ = sigmoide(x@w.T)\n",
        "      #print(\"y: \", y.shape,\"y_: \", y_.shape, \"x: \",x.shape, \"w: \", w.shape)\n",
        "      w = w - (lr/m) * sum((x.T*(y_ - y)).T)\n",
        "      cost.append(meanCost(w, x, y))\n",
        "\n",
        "    return w, cost\n",
        "\n",
        "  def accuracy(self, y_, y):\n",
        "    vp = 0\n",
        "    vn = 0\n",
        "    fp = 0\n",
        "    fn = 0\n",
        "\n",
        "    for i in range(len(y)):\n",
        "      if(y_[i] == y[i] and y_[i] == 1):\n",
        "        vp+=1\n",
        "      elif(y_[i] == y[i] and y_[i] == 0):\n",
        "        vn+=1\n",
        "      elif(y_[i] != y[i] and y_[i] == 1):\n",
        "        fp+=1\n",
        "      elif(y_[i] != y[i] and y_[i] == 0):\n",
        "        fn+=1\n",
        "    print(\"accuracy: \", (vp+vn)/(vp+vn+fp+fn))\n",
        "\n",
        "\n",
        "  def train(self, w, x, y, lr, epochs):\n",
        "    print(\"--------------------Train--------------------\")\n",
        "    w, cost = self.logisticGradientDesc(w, x, y, lr, epochs)\n",
        "    return w, cost\n",
        "\n",
        "\n",
        "  def test(self, w, x, y):\n",
        "    print(\"--------------------Test--------------------\")\n",
        "    #print(x[0,:])\n",
        "    bce = (sigmoide(x@w.T))\n",
        "    #print(bce)\n",
        "    result = []\n",
        "    for i in bce:\n",
        "      #print(i)\n",
        "      if i >= 0.5:\n",
        "        result.append(1)\n",
        "      else:\n",
        "        result.append(0)\n",
        "    #print(np.asarray(result))\n",
        "    #print(y)\n",
        "    self.accuracy(result, y)\n",
        "\n",
        "  def run(self):\n",
        "    print(\"Learning Rate: \", lr)\n",
        "    print(\"Epochs: \", epochs)\n",
        "    print(\"X_Train: \", x_train.shape)\n",
        "    print(\"Y_Train: \", y_train.shape)\n",
        "    print(\"X_Test: \", x_test.shape)\n",
        "    print(\"Y_test: \", y_test.shape)\n",
        "\n",
        "    self.w, cost = self.train(self.w, self.x_train, self.y_train, self.lr, self.epochs)\n",
        "    self.test(self.w, self.x_test, self.y_test)\n",
        "    \n",
        "    #print(w)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Desafio"
      ],
      "metadata": {
        "id": "LNhYIwM7qeDp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dados=load_breast_cancer() # Carregando base de dados\n",
        "\n",
        "# vamos ver a descrição de nossa base de dados\n",
        "#print(dados.DESCR)\n",
        "\n",
        "cancer=pd.DataFrame(data=dados.data, columns=dados.feature_names) # convertendo para dataframe com ajuda do Pandas\n",
        "\n",
        "cancer['Class']=dados.target # Adicionando a nossa Target\n",
        "#!wget https://raw.githubusercontent.com/sandeco/CanalSandeco/master/Deep%20Learning%20s%C3%A9rie/%2306%20-%20GD%20M%C3%BAltiplas%20Vari%C3%A1veis/prices.csv\n",
        "#df = pd.read_csv('prices.csv', on_bad_lines='skip')\n",
        "\n",
        "# primeiro vamos dividir nossa base de dados entre features e target\n",
        "X = cancer.iloc[:,0:-1]# Selecionando todas as linhas, da primeira coluna até a penúltima coluna.\n",
        "Y = cancer.iloc[:,-1] # Selecionando todas as linhas da última coluna ['Class'].\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.30, random_state=42)\n",
        "\n",
        "epochs = 100\n",
        "x = np.asarray(x_train)\n",
        "x = (x - x.mean()) / x.std()       ##normalization\n",
        "y_train = np.asarray(y_train)      ##convert in to numpy array\n",
        "x_train = extendX(x)               ##extend with ones\n",
        "\n",
        "x = np.asarray(x_test)\n",
        "x = (x - x.mean()) / x.std()       ##normalization\n",
        "y_test = np.asarray(y_test)        ##convert in to numpy array\n",
        "x_test = extendX(x)                 ##extend with ones\n",
        "\n",
        "lr = 0.01\n",
        "\n",
        "w = np.ones(x_train.shape[1])/10\n",
        "\n",
        "logr = LogisticRegression(lr, epochs, x_train, y_train, x_test, y_test)\n",
        "logr.run()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HhBLiRfOorNn",
        "outputId": "1aa7b269-24a3-4df4-dee1-ccd8b6d07588"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Learning Rate:  0.01\n",
            "Epochs:  100\n",
            "X_Train:  (398, 31)\n",
            "Y_Train:  (398,)\n",
            "X_Test:  (171, 31)\n",
            "Y_test:  (171,)\n",
            "--------------------Train--------------------\n",
            "--------------------Test--------------------\n",
            "accuracy:  0.9415204678362573\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7EOviQQZpAyn"
      },
      "execution_count": 16,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}